# Test #1

![RPS](./src/500users-1rps.png)

Настройки запуска нагрузочного тестирования. Увеличение пользователей на 25, всего пользователей 500, 1запрос/1секунда

На протяжении времени количество RPS держалось около 480-490, без срабатываний timeout'ов, или исключений.

CPU был загружен на 100%, через 5-10 секунд, после завершения тестирования, потребовалось, что бы задачи закончились из стека задач.

---

# Test #2

![RPS](./src/500users-4rps.png)


Настройки запуска нагрузочного тестирования. Увеличение пользователей на 25, всего пользователей 500, 4запросов/1секунда

На протяжении времени количество RPS держалось около 650-710, без срабатываний timeout'ов, или исключений.

CPU был загружен на 100%, через 20-30 секунд, после завершения тестирования, потребовалось, что бы задачи закончились из стека задач.

---

## Техническое оборудование:

* __CPU__ - AMD Ryzen 7 5800x 8-Core
* __RAM__ - DDR4 Kingston 2666 2 потока 4 плашки, каждая по 8 ГБ

---

## Замечания и наблюдения:

Во время тестирования, CPU в обоих случаев загружена на 100%, разница лишь в скорости пополнения стека задач (rabbitmq)

RAM в обоих случаев нагружался до 50-55%, сервисы все запускались в docker, тесты запускались локально (не внутри docker'a)

Во втором случае замечен баг, который в скором будет поправляться, в бд просочились дубликаты, а именно 4 дубликата прошли сквозь систему,
предполагаю, что 4 запроса отправилось и в redis и в db, 4 воркера в одно и тоже время взяли задачу, которые были одинаковы и выполнялись в одно и тоже время

Предполагаемое решение, смотреть в сторону redis....

---

# Test #3

![RPS](./src/500users-4rps_2.png)

Настройки запуска нагрузочного тестирования. Увеличение пользователей на 25, всего пользователей 500, 4запроса/1секунда

На протяжении времени количество RPS увеличилось до 970-990, без срабатываний timeout'ов, или исключений.

CPU был загружен на 60-70%.

---

## Замечания и наблюдение:

После исправления бага с дубликатом, производительность увеличилась, но нужно учесть, что все данные были одинаковы, 
следующее исследование будет проводиться при разном количестве данных у пользователей.

Техническая аппаратура не изменилась, CPU в последнем тесте было нагружено на 60-70%, а память в тех же цифрах 50-60%


# Test #4

![RPS](./src/500users-4rps_3.png)

Настройки запуска нагрузочного тестирования. Увеличение пользователей на 25, всего пользователей 500, 4 запроса/1секунда, рандомные данные.

Стоит акцентировать внимание на то, что когда шли рандомные данные и данные были уникальны, RPS держалось в районе 450-500, 
как только данные начали повторяться RPS увеличивалось до 600

CPU в момент, когда данные были уникальны загрузилось до 100%, как только данные начали повторяться нагрузка на CPU снизилось до 80-90%,
а память на протяжении всего теста было в районе 50-60%.

---

## Замечания и наблюдение:

Как только шла нагрузка на бд, CPU загружалось по максимум, как только нагрузка с бд упала, загрузка CPU так же - упала.

Вывод: БД ЗЛО!!!! (Снизить нагрузку на БД, или заменить её на что-то менее загружаемое, но это уже другая история)


# Test #5

![RPS](./src/500users-4rps_4.png)

Настройки запуска нагрузочного тестирования. 
Увеличение пользователей на 25, 
всего пользователей 500, 
4запрос/1секунда, рандомные данные.

Добавлен Filter Bloom (собственная библиотека). 

CPU в момент, когда данные сохранялись в clickhouse - нагрузка составляла 100%,
во время добавления данных возросла и нагрузка на RAM, с 60% до 80% и держалась на протяжении всего теста,
как только начали идти дубликаты, нагрузка с CPU уменьшилась на 40 %, 
загруженность CPU составляла около 60%, а на памяти нагрузка прыгала с 60-80%

Во время добавления уникальных данных (в начале запуска) RPS держалось в районе 450-500, 
как только дубликаты начали появляться RPS увеличилось до 600, 
как только данные стали все дубликатами, RPS увеличилось до 700 и прыгала в районе 650-700

---

## Замечания и наблюдения:

С подключением bloom filter нагрузка в CPU упала, 
но тяжело организовать имитацию дублирующих запросов вместе с уникальными данными, что бы максимально имитировать поведение сервиса.

Я пока не вижу смысла убирать звенья, то есть сейчас проект работает так:

Filter Blooms -> Redis -> Clickhouse

Если я убираю filter bloom появляется нагрузка на redis, а после и на clickhouse, убирая Redis появляется нагрузка на clickhouse, убирая clickhouse, умирают данные.
И в своей реализации я не вижу путей, где бы мог сотворить какую-то магию, в рамках данного проекта.
